-> Sincronizzazione e comunicazione tra processi

I processi hanno bisogno di un modo per comunicare in modo da condividere i dati e di sincronizzarsi con altri processi durante l'esecuzione.
Molto brevemente, i problemi sono 3. Il primo è relativo al modo in cui un processo può passare informazioni ad un altro. Il secondo è accettarsi che due o più processi o thread
non si intralcino a vicenda.
Il terzo riguarda la corretta sequenzialità quando vi sono delle dipendenze: se il thread A produce dei dati e il thread B li stampa, B deve attendere che A abbia prodotto qualche 
dato prima di iniziare a stampare.

# Race Conditions
I processi possono lavorare insieme condividendo una parte di memorizzazione comune che ciascuno puo leggere e scrivere. Questa memorizzazione condivisa puo trovarsi nella memoria principale o puo essere un file condiviso.
Situazioni in cui duo o piu processi leggono o scrivono i medesimi dati condivisi e il risultato finale dipende dai tempi precisi in cui vengono eseguiti, sono chimate race conditions.
Ovvero, i processi "corrono" insieme per ottenere l'accesso ad una risorsa.

# Regione Critica
Per evitare le race conditions serve una mutua esclusione, ossia un qualche sistema per essere certi che, se un processo sta usando un variabile o un file condiviso, agli altri 
processi venga impedito di fare la stessa cosa. La parte di programma in cui accede alla memoria condivisa è chiamata regione critica o sezione critica, quindi la soluzione alle
race conditions è di non fare accedere due processi/thread in contemporanea nella regione critica. Per ottenere una buona soluzione servono 4 condizioni da rispettare:

1. Due processi non possono trovarsi contemporaneamente all'interno delle rispettive regioni critiche
2. Non si possono fare ipotesi sulla velocità o sul numero di CPU
3. Nessun processo in esecuzione a di fuori della propria regione critica puo bloccare altri processi
4. Nessun processo deve aspettare all'infinito per entrare nella propria regione critica

# Mutua Esclusione con Busy Waiting

(a) Disabilitare gli interrupt di un processo appena entrato nella sua regione critica e li riabiliti quando ne esce. 
In questo modo non c'e la possibilita che un altro processo entri nella regione critica, perche la riallocazione della CPU avviene ad ogni interrupt di clock e di altri interrupt. 
E' una tecnica che puo essere usata solo dal kernel per aggiornare alcuni dati critici, ma non è opportuno dare la possibilita ai processi utente di disabilitare gli interrupt.
Funziona solo per sistemi a CPU singola (single core), perche nei sistemi multicore, se gli interrupt di un core vengono disabilitati, gli altri core possono comunque interferire.

(b) Bloccare le variabili, proteggere le regioni critiche con variabili 0/1. Le 'corse' si verificano ora sulle variabili di blocco.

(c) Alternanza Stretta

La variabile turn, inizialmente a 0 tiene traccia dei turni dei processi che vogliono entrare nella regione critica.
Il processo A vede che turn è 0, quindi entra nella regione critica impostando turn a 1, nel mentre il processo B vede che turn è 1 quindi si mette in attesa in un rapido ciclo.
L'azione di testare continuamente una variabile finché non è valorizzata
si chiama busy waiting. Andrebbe generalmente evitato, dato che consuma tempo alla CPU. Di solito si usa quando l'attesa è relativamente breve.

- Processo A
while(TRUE){
    while(turn != 0); 
    // turn è la variabile globale, un ciclo che non fa nulla, oltre al controllo
    // nel momento che turn == 0, il thread esegue critical_region()
    // turn viene impostato a 0 nel momento in cui B esce dalla regione critica
    critcal_region();
    turn = 1;
    // imposta turn = 1, quindi esce dalla regione critica è permette a B di entrarci
    noncritical_region();  
}

- Processo B
while(TRUE){
    while(turn != 1); 
    // turn è la variabile globale, un ciclo che non fa nulla, oltre al controllo
    // nel momentp che turn == 1, il thread esegue critical_region()
    // turn viene impostato a 1 nel momento in cui A esce dalla regione critica
    critcal_region();
    turn = 0;
    // imposta turn = 0, quindi esce dalla regione critica è permette ad A di entrarci
    noncritical_region(); 
}

Purtroppo, questa è un altra non soluzione perche:
- Non permette ai processi di entrare nelle loro regioni critiche per due volte di seguito.
- Un processo fuori dalla regione critica può effettivamente bloccarne un altro violando la 3 condizione.

(d) Peterson's Algorithm

Alice e Bob vogliono usare un'unica postatione computer in un ufficio. Ma ci sono delle regole:
1. Solo una persona puo usare il computer alla volta.
2. Se entrambi vogliono usarlo contemporaneamente, devono decidere chi va per primo.

Idea:
Alice e Bob devono segnalare il loro interesse a usare il computer.
Se l'altro non è interessato, la persona interessata puo usarlo subito.
Se entrambi mostrano interesse, registrano il loro nome su un foglio. Ma se scrivono quasi allo stesso tempo, l'ultimo nome sul foglio ha precedenza.
    Perche: garantisce che sempre uno avrà scritto e l'ultimo sarà quello che si prende la risorsa.
La persona che non ha la precedenza aspetta finché l'altra ha finito.
Una volta finito, la persona che ha usato il computer segnala che ha finito, e l'altra puo iniziare.

Algorithm
#define N 2 // numero di processi

int turn; // a chi tocca?
int interested[N] // tutti i valori inizialmente 0 [FALSE]

void enter_region(int process){ // process è 0 o 1
    int other;  // numero dell'altro processo
    other = 1 - process;  // l'opposto del processo
    interested[process] = TRUE; // mostra che si è interessati
    turn = process; // imposta il flag
    // tra interested[process] = TRUE e il while a livello di CPU puo passare anni, quindi nel mentre l'altro processo puo interessarsi alla risorsa
    while(turn == process && interested[other] == TRUE) // istruzione NULL
    // aspetto affinche other perde l'interesse alla risorsa.
}
void leave_region(int process){ // process: chi esce
  interested[process] = FALSE;  // indica l'uscita dalla regione critica
}

(e) TSL e XCHG

- Istruzione TSL (Test and Set Lock)
E presente in computer con piu processori. Legge il contenuto della memoria "lock", salva un valore non zero, e blocca altre CPU da accesso alla memoria.
Purtroppo anche disabilitando gli interrupt su un processore non c'è garanzia che un processo " non faccia danni" da un'altra CPU e quindi, blocchiamo tutti fino al termine dell'esecuzione di TSL.
Se devo aggire su una variabile, addirittura blocco tutti gli altri ad aggire sulla variabile. Vene fatto solo per operazioni atomiche, come per assegnare un valore.

Funzionamento:
Quando lock è 0, un processo puo impostare lock a 1 con TSL e accedere alla memoria condivisa. Al termine, il processo ressetta lock a 0.
Metodo per gestire Regioni Critiche:
- Processi chiamano enter_region prima di entrare nella regione critica e leave_region dopo.
- Se chiamati correttamente, garantisce la mutua esclusione.
- Se usati in modo errato, la mutua esclusione fallisce.

- Codice Assembly
enter_region:
    TSL REGISTER, LOCK // copia il lock nel registro e lo imposta a 1
    CMP REGISTER, #0 // il lock era 0?
    JNE enter_region // se non era 0, il lock era stato impostato, per cui ri-esegui il ciclo
    RET // torna al chiamante, si è entrati nella regione critica
leave_region:
    MOVE LOCK, #0 // memorizza 0 il lock
    RET // torna al chiamante


- Istruzione XCHG
Scambia i contenuti di due posizioni atomicamente. Usata in tutte le CPU x86 Intel per sincronizzazione di basso livello.

# Sleep e Wakeup

Problema:
Nonostante con l'algoritmo di Peterson funzioni, rimane il problema dello speco delle risorse causato dal busy waiting, il processo tiene occupata la CPU in attesa di poter entrare nella sua regione critica (spin lock).
Soluzione:
Lasciare che un processo in attesa di entrare nella sua regione critica restituisca volontariamente la CPU allo scheduler.

void sleep(){
    set own state to BLOCKED;
    give CPU to scheduler;
}

void wakeup(process){
    set state of process to READY;
    give CPU to scheduler;
}   

Problema Produttore-Consumatore

Nel problema del produttore-consumatore, due proessi condividono un buffer di dimensioni fisse.
Il produttore inserisce informazioni nel buffer, mentre il consumatore le preleva.
In produttore si addormenta (entra in modalità "sleep") se il buffer è pieno e viene risvegliato ("wakeup") quando il consumatore preleva i dati.
Analogamente, il consumatore dorme se il buffer è vuoto e viene risvegliato quando il produttore inserisce dati.

#define N 100
int count = 0;

void producer(void){
    int item;
    while(TRUE){
        item = produce_item();
        if(count == N) sleep(); // se ho prodotto N elementi vado in sleep (libero la CPU)
        insert_item(item); // se ci sono <N elementi allora continuo a produrli
        count++; // aggiorno il contatore
        if(count == 1) wakeup(cons) // se c'e almeno un prodotto sveglio il consumatore
    }
}

void consumer(void){
    int item;
    while(TRUE){ 
        if(count == 0) sleep() // se non ci sono elementi, vado in sleep (libero la CPU)
        item = remove_item(); // se c'e almeno un elemento lo rimuovo
        count--; // aggiorno il contatore
        if(count == N - 1) wakeup(prod); // se ci sono <N elementi allora sveglio il produttore
        consume_item(item);
    }
}

Problema: il produttore potrebbe svegliare il consumatore un attimo prima di andare in sleep(), e nessuno lo risveglierebbe piu, perche non potendo piu consumare,
il produttore non sa se deve produrre o no.

# Semafori

Fondamentalmente il semaforo è una variabile che puo essere 0 (nessun wakeup) oppure un valore positivo (wakeup in attesa) e
su questa variabile si possono eseguire le seguenti operazioni:
- down
  Se il valore del semaforo è maggiore di zero, questo valore viene decrmentato, e il processo continua la sua esecuzione.
  Se il valore del semaforo è 0, il processo che ha invocato down viene bloccato e messo in una coda di attesa associata al semaforo (va a dormire, sleep()).

- up
  Se il valore è 0, ci sono processi nella coda di attesa, vengono "svegliati" (eventualmente per entrare in competizione ed eseguire di nouvo down).
  In ogni caso, il valore viene incrementato e il processo continua la sua esecuzione.

Atomicita: Le operazioni sui semafori sono "indivisibili", evitando conflitti
Problma Produttore-Consumatore: Uso dei semafori per gestire accesso e capacità di un buffer.
- Tipi di semafori
  mutex (mutual exclusion, accesso esclusivo).
  full (tutti i posti occupati).
  empty (tutti posti liberi).
-Uso
  mutex previene eccessi simultanei, full e empty coordinano attività.
{6.2_produce_consumer_semaphore.c}

Problema scrittori e lettori 

Regola: Ci sono tanti lettori(consumer) e un solo scrittore(producer)
Esempio: Si possono avere molteplici letture su un database, ma solo un singolo scritore.
Funzionamento Sintetico: 
    - Il primo lettore blocca l'accesso al database.
    - Lettori successivi incrementano un contatore.
    - L'ultimo lettore libera l'acccesso al database cosi lo scrittore può svolgere il suo lavoro.
{6.3_reader_writer_semaphore.c}
Uso semafori: sincronizzare piu processi tra loro.

# Mutex

Un "mutex" è una versione esplicita e semplicifacata dei semafori, usata per gestire la mutua esclusione di risorse o codice condiviso, quando non bisogna contare accessi e altri fenomeni.
Può essere in due stati:
- locked (bloccato)
- unlocked (sbloccato)
Un bit basta per rappresentarlo, ma spesso viene usato un intero (0 - unlocked, altri - locked)
Due procedure principali: mutex_lock e mutex_unlock
- Quando un thread vuole accedere a una regione critica, chiama mutex_lock.
- Se il mutex è unlocked, il thread può entrare; se è locked, il thread attende.
- Al termine dell'accesso, il thread chimata mutex_unlock per liberare la risorsa.
- IMPORTANTE: non si utilizza il busy waiting. Se un thread non puo acquisire un lock, chiama thread_yield per cedere la CPU ad un altro thread.
- I mutex possono essere implementati nello spazio utente con istruzioni come TLS e XCHG
- Alcuni pacchetti di thread offrono mutex_trylock che, tenta di acquisire il lock o restituisce un errore, senza bloccare. 
    Offre la possibilita di provare a prendere lock, se non è gia occupato non si blocca ma continua ad eseguire altro, non sprecando tempo.
- I mutex sono efficaci quando i thread operano in uno spazio degli indirizzi comune.
- La condivisione di memoria tra processi può essere gesitita tramite il kernel o con l'aiuto di sistemi operativi che permettono la condivisione di parti dello spazio degli inidirizzi.
- L'efficienza nella sincronizzazione diventa cruciale con l' aumento del parallelismo
- Spin lock e mutex con busy waiting: efficaci per attese brevi, ma sprecano CPU per attese lunghe.
- Passaggio al kernel per bloccare processi è oneroso se le contese sono poche.
- Soluzione: Futex (Fast User Space Mutex), combina il meglio di entrambi gli approcci.

Mutexes in Pthead
La libreria Posix Pthead fornisce funzioni per sincronizzazione tra thread.
Il mutex è una variabile che puo essere locked o unlocked ed è utilizzato per proteggere le regioni critiche.
Il thread tenta di bloccare (lock) un mutex per accedere alla regione critica. Se mutex è unlocked, l'accesso è immediato e atomico. Se locked il thead attende.

- pthead_mutex_init: crea il mutex
- pthead_mutex_destroy: distrugge il mutex
- pthead_mutex_lock: acquisisce il mutex o si blocca
- pthead_mutex_trylock: acquisisce il mutex o fallisce
- pthead_mutex_unlock: rilascia il mutex
- pthead_cond_init: crea una variabile condizionale
- pthead_cond_destroy: distrugge una variabile condizionale
- pthead_cond_wait: si blocca in attesa di un segnale
- pthead_cond_signal: segnala un altro thread e lo sveglia
- pthead_cond_broadcast: segnala multipli thread e li sveglia

# Semafori o Mutex?
- Finalità
  Mutex: E' utilizzato principalmente per garantire l'esclusione mutua. E' destinato a proteggere l'accesso a una risorsa condivisa, garantendo che una solo thead possa accedervi alla volta.
  Semaforo: Può essere usato per controllare l'accesso a una risorsa condivisa, ma è anche spesso usato per la sincronizzazione tra thread.

- Semantica
  Mutex: Di solito ha una semantica di "proprietà", il che significa che solo il thread che ha acquisito il mutex può rilascirarlo
  Semaforo: Non ha una semantica di "proprietà". Qualsiasi thead può aumentare o diminuire il conteggio del semaforo, indipendentemente da chi lo ha modificato l'ultima volta.

- Casistica
  Per l'esclusione mutua: Un mutex è generalmente preferibile. 
  E' più semplice (di solito ha operazioni di lock e unlock) e spesso offre una semantica più rigorosa e un comportamento più prevedibile.
  Per la sincronizzazione tra thread: Un semaforo può essere più adatto,
  specialmente quando si tratta di coordinare tra diversi thread o di gestire risorse con un numero limitato di istanze disponibili.
{6.4_produce_consumer_mutex.c}

NOTA
- Protezione della risorsa condivisa: pthead_mutex_lock assicura che solo un thread alla volta possa accedere e modificare la risorsa condivisa.
- Attesa condizionale: Quando un thread chiama pthead_cond_wait, due operazioni avvengono atomicamente,
    il thread rilascia il mutex e mette il thread in uno stato di attesa sulla variabile condizionale.
Quindi anche se il produttore ha acquisito il mutex, non lo detiene mentre è in attesa sulla variabile condizionale.
Questo permette al consumatore (o a un altro thread) di acquisire il mutex, fare le sue operazioni, e poi mandare un segnale alla variabile condizionale usando pthead_cond_signal.

# Monitor

Un monitor raggruppa provedure, variabili e strutture dati. I processi possono chiamare le procedure di un monitor ma non possono accedere direttamente alle sue strutture dati interne.
Solo un processo puo essere attivo in un monitor in un dato momento, garantendo la mutua esclusione. Il compilatore gestisce la mutua esclusione dei monitor, riducendo la 
probabilità di errori da parte del programmatore. Per gestire situazioni in cui i processi devono attendere, i monitor utilizzano variabiali condizionali e due operazioni su di esse:
wait e signal. A differenza dei semafori, le variabili condizionali non accumulano segnali, se un segnale viene inviato e non c'è un processo in attesa, il segnale viene perso.
Linguaggi come Java supportano i monitor, permettendo una sincronizzazione e mutua esclusione più sicura e semplice in contesti multithreading. I metodo sono dichiarati syncronized
in modo che solo un thread può accedervi.

# Scambio di Messaggi

Metodo di comunicazione tra processi usando due primitive: send(dest, &msg) e receive(src, &msg). Puo essere utilizzato in diversi scenari, compresi sitemi distribuiti.
Problemi:
- Messaggi persi in rete 
- Necessità di feedback per confermare la ricezione
- Gestione dei messaggi duplicati usando numeri sequenziali 
- Autenticazione e denominazione dei processi
Malgrado l'inaffidabilità, lo scambio di messaggi è cruciale nello studio delle reti.

Problema del produttore-consumatore:
Soluzione senza memoria condivisa usando solo messaggi.
Utilizza un totale di N messaggi, simili ai N posti del buffer nella memoria condivisa.
Il consumatore invia al produttore N messaggi vuoti
Il produttore prende un messaggio vuoto, lo riempie e lo invia

# Barriere

Le barriere sono utilizzate per sincronizzare processi in fasi diverse. Quando un processo raggiunge una barriera, attende fono a quando tutti gli altri processi la raggiungono.
Per esempio in calcoli paralleli su matrici, i processi non possono avanzare a un'iterazione successiva finché tutti non hanno terminato l'iterazione attuale.
Sono utilizzate per sincronizzare processi in fasi diverse. 
{immgaine}

# Inversione delle Priorità

Dati tre thread T1, T2, T3 con rispettive priorità p1 > p2 > p3
Supponiamo che T1 e T3 debbano accedere alla risorsa alla quale è associato il mutex S

Se T3 inizia ad essere processato e fa un lock(S) prima che T1 parta allorquando T1 partirà e tenterà di fare un lock(S) verrà bloccato per un tempo non definito,
cioè fino a quando T3 non farà un unlock(S) liberando la risorsa 'S'. T1 infatti non può continuare l'esecuzione senza la risorsa 'S' detenuta da T3.
Risulta evidente che in questo caso T1 venga penalizzato a favore di T3 a dispetto dell'ordine delle priorità p1>p3 (caso di blocco diretto).

Se, prima che T3 faccia un unlock(S), parte il T2 (che non utilizza la risorsa S), allora T3 verrà sospeso per permettere a T2 di essere processato in virtù delle priorità p2>p3.
In questo caso T1 dovrà attendere che anche T2 finisca di essere processato. Infatti T1 è bloccato su T3 che a sua volta è bloccato su T2 a dispetto dell'ordine delle priorità p1>p2
(caso di blocco indiretto). 

Soluzioni:
- Disattivare gli interrupt
- Priority Ceiling, ovvero assegnare una priorità al mutex. La priorità viene assegnata al processo che detiene il mutex. Fintanto che nessun processo che deve acquisire il mutex ha
una priorità superiore al limte, l'inversione non è più possibile.
- Priority Inheritance, task a bassa priorità che detiene il mutex eredita temporaneamente la priorità del task ad alta priorità
- Random Boosting, aumenta la priorità di thread casuali che detengono il mutex

# Read-Copy-Update

L'obiettivo è di accedere in modo concorrente senza lock, l'unico problema è l'incosistenza dei dati.
L'idea è di aggiornare strutture dati consentendo letture simulatee senza incappare in versioni inconsistenti dei dati, i lettori o vedono la versione vecchia o quella nuova, 
mai un mix delle due.
{immagine}

E' diffuso nel kernel dei sistemi operativi.







